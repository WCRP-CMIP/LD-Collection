{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, sys, time, requests, argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download(user,repo,branch='main',path='data_descriptors'):\n",
    "\n",
    "#     # cmd = f'git archive --remote=git@github.com:{user}/{repo}.git {branch} {path} | tar -xvf -'\n",
    "#     cmd = f'wget --recursive --no-parent --no-directories -P ./downloaded-folder/ \\\n",
    "#     --accept \"*.*\" https://api.github.com/repos/{user}/{repo}/contents/{path}?ref={branch}'\n",
    "#     print(cmd)\n",
    "#     os.popen(cmd)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def download_file(download_url, file_path):\n",
    "    \"\"\"Downloads a single file.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(download_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded: {file_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {file_path}: {response.status_code} - {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {file_path}: {e}\")\n",
    "\n",
    "def process_folder(owner, repo, folder, branch, output_dir):\n",
    "    \"\"\"\n",
    "    Processes a folder: Downloads files and recurses into subdirectories.\n",
    "    \"\"\"\n",
    "    api_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{folder}?ref={branch}\"\n",
    "    response = requests.get(api_url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch folder contents: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "    files = response.json()\n",
    "    tasks = []\n",
    "    for file in files:\n",
    "        if file[\"type\"] == \"file\":\n",
    "            # File download task\n",
    "            file_path = os.path.join(output_dir, folder, file[\"name\"])\n",
    "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "            tasks.append((file[\"download_url\"], file_path))\n",
    "        elif file[\"type\"] == \"dir\":\n",
    "            # Recurse into subdirectory\n",
    "            subfolder = os.path.join(folder, file[\"name\"])\n",
    "            tasks.extend(process_folder(owner, repo, subfolder, branch, output_dir))\n",
    "\n",
    "    return tasks\n",
    "\n",
    "def download(owner, repo, folder='data_descriptors', branch='main', output_dir='./downloads', max_workers=8):\n",
    "    \"\"\"\n",
    "    Downloads all files from a specific folder in a GitHub repository, including nested directories.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    tasks = process_folder(owner, repo, folder, branch, output_dir)\n",
    "\n",
    "    # Use ThreadPoolExecutor to download files in parallel\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(download_file, url, path) for url, path in tasks]\n",
    "        for future in futures:\n",
    "            future.result()  # Wait for all downloads to complete\n",
    "\n",
    "    print(\"All downloads completed.\")\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     download(\n",
    "#         owner=\"your-username\",\n",
    "#         repo=\"CRP-UNIVERSE\",\n",
    "#         branch=\"main\",\n",
    "#         folder=\"data_descriptors\",\n",
    "#         output_dir=\"./downloaded-folder\",\n",
    "#         max_workers=8  # Adjust the number of threads for optimal performance\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ./downloads/CMIP7/data_descriptors/.DS_StoreDownloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/c4mip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/_context\n",
      "\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/cfmip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/cmip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/.DS_Store\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/_context_\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/aerchemmip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/scenariomip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/dcpp.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/damip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/geomip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/lmip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/rfmip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/activity/THESE NOW EXIST IN WCRP UNIVERSE/pmip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/.DS_Store\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/1pctco2-bgc.jsonDownloaded: ./downloads/CMIP7/data_descriptors/experiment/1pctco2.json\n",
      "\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/1pctco2-rad.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/_context_\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/abrupt-2xco2.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/abrupt-0p5co2.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/abrupt-4xco2.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/amip-p4k.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/amip.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/amip-piforcing.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/esm-flat10-zec.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/esm-flat10-cdr.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/esm-hist.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/g7-15k-sai.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/esm-picontrol.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/graph.jsonld\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/hist-piaer.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/hist-ghg.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/high-scenario.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/hist-nat.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/hist-aer.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/historical.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/hist-pislcf.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/initialised-prediction-2025-2036.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/land-hist.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/medium-scenario-and-extension.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/low-scenario.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-4xco2.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/ligabrupt.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-aer.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/low-overshoot-scenario.json\n",
      "Error downloading ./downloads/CMIP7/data_descriptors/experiment/piclim-histall.json: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /WCRP-CMIP/CMIP7_CVs/main/data_descriptors/experiment/piclim-histall.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1044c95a0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-anthro.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-ch4.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-control.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-hc.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-histaer.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-n2o.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-so2.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-nox.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/piclim-voc.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/sspx-slcf.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/picontrol.json\n",
      "Downloaded: ./downloads/CMIP7/data_descriptors/experiment/very-low-scenario.json\n",
      "All downloads completed.\n"
     ]
    }
   ],
   "source": [
    "download('wcrp-cmip','CMIP7_CVs',output_dir='./downloads/CMIP7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(\u001b[43mcontents\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'contents' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
